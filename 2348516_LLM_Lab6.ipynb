{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3NVQ2wnQXaz8oy6f7nDe5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elizabeth-George-M/LLM/blob/main/2348516_LLM_Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jxHuM3pxZKA",
        "outputId": "f9aaf7aa-0464-4fa7-bb2e-c69b2bbbd8fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "slxr41TDxY8x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "desLEKEAxq8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text, vocab=None):\n",
        "    tokens = text.lower().split()\n",
        "    if vocab:\n",
        "        tokens = [vocab[token] if token in vocab else vocab[\"\"] for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    vocab = {\"\": 0, \"\": 1, \"\": 2, \"\": 3}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence.lower().split():\n",
        "            if word not in vocab:\n",
        "                vocab[word] = len(vocab)\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "eTFCsEQQxY3A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Creation"
      ],
      "metadata": {
        "id": "3R1iLSGnxu0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, trg_sentences, src_vocab, trg_vocab):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.trg_sentences = trg_sentences\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = tokenize(self.src_sentences[idx], self.src_vocab)\n",
        "        trg = tokenize(self.trg_sentences[idx], self.trg_vocab)\n",
        "        return torch.tensor(src, dtype=torch.long), torch.tensor(trg, dtype=torch.long)\n",
        "\n",
        "src_sentences = [\"I am a student\", \"You are a teacher\"]\n",
        "trg_sentences = [\"Je suis un étudiant\", \"Vous êtes un enseignant\"]\n",
        "\n",
        "src_vocab = build_vocab(src_sentences)\n",
        "trg_vocab = build_vocab(trg_sentences)\n",
        "\n",
        "dataset = TranslationDataset(src_sentences, trg_sentences, src_vocab, trg_vocab)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: x)"
      ],
      "metadata": {
        "id": "h93GTepLxuRg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Creation"
      ],
      "metadata": {
        "id": "hfRfN1mfx4oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.trg_embedding = nn.Embedding(trg_vocab_size, d_model)\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, 100, d_model))  # assuming max sentence length is 100\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
        "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src = self.src_embedding(src) + self.positional_encoding[:, :src.size(1), :]\n",
        "        trg = self.trg_embedding(trg) + self.positional_encoding[:, :trg.size(1), :]\n",
        "        src = src.permute(1, 0, 2)\n",
        "        trg = trg.permute(1, 0, 2)\n",
        "\n",
        "        out = self.transformer(src, trg)\n",
        "        out = self.fc_out(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "B9J8G7Wyx0PR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(src_vocab)\n",
        "trg_vocab_size = len(trg_vocab)\n",
        "\n",
        "model = Transformer(src_vocab_size, trg_vocab_size)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab[\"\"])\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJOoccR-x36t",
        "outputId": "db2bd8a2-a3c6-4180-819a-0c85281d6342"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=src_vocab[\"\"], batch_first=True)\n",
        "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=trg_vocab[\"\"], batch_first=True)\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "MoizvzA7x9aa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):  # number of epochs\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch in dataloader:\n",
        "        src, trg = batch  # unpack the batch directly into src and trg tensors\n",
        "        trg_input = trg[:, :-1]  # remove the last token for the input to the decoder\n",
        "        trg_output = trg[:, 1:].contiguous().view(-1)  # shift target for comparison with output\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg_input)\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        loss = criterion(output, trg_output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPC2k9F6x_2O",
        "outputId": "2807500c-d27a-4ee9-b938-ed29632c9f5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.4435815811157227\n",
            "Epoch 2, Loss: 1.4568657875061035\n",
            "Epoch 3, Loss: 3.148031234741211\n",
            "Epoch 4, Loss: 1.2495932579040527\n",
            "Epoch 5, Loss: 1.3277418613433838\n",
            "Epoch 6, Loss: 1.150696039199829\n",
            "Epoch 7, Loss: 0.7243847846984863\n",
            "Epoch 8, Loss: 0.9098981022834778\n",
            "Epoch 9, Loss: 1.030714750289917\n",
            "Epoch 10, Loss: 0.8607925176620483\n",
            "Epoch 11, Loss: 0.673680305480957\n",
            "Epoch 12, Loss: 0.7857436537742615\n",
            "Epoch 13, Loss: 0.7646663784980774\n",
            "Epoch 14, Loss: 0.7549762725830078\n",
            "Epoch 15, Loss: 0.7856367826461792\n",
            "Epoch 16, Loss: 0.7142279148101807\n",
            "Epoch 17, Loss: 0.7735351324081421\n",
            "Epoch 18, Loss: 0.8886959552764893\n",
            "Epoch 19, Loss: 0.7747910618782043\n",
            "Epoch 20, Loss: 0.8869290351867676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    src_sentence = \"I am a student\"\n",
        "    src = torch.tensor(tokenize(src_sentence, src_vocab), dtype=torch.long).unsqueeze(0)  # shape: [1, src_len]\n",
        "    trg = torch.tensor([trg_vocab[\"\"]], dtype=torch.long).unsqueeze(0)  # shape: [1, 1]\n",
        "\n",
        "    for i in range(100):  # maximum output sentence length\n",
        "        output = model(src, trg)  # output shape: [trg_len, batch_size, vocab_size]\n",
        "        next_word = output[-1, 0, :].argmax(0).item()  # get the last word's prediction for the batch\n",
        "\n",
        "        trg = torch.cat((trg, torch.tensor([[next_word]], dtype=torch.long)), dim=1)\n",
        "        if next_word == trg_vocab[\"\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = \" \".join([list(trg_vocab.keys())[idx] for idx in trg.squeeze(0).tolist()])\n",
        "    print(f'Translated Sentence: {translated_sentence}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yy8cydRyCYz",
        "outputId": "83064b09-7ce3-444a-fa9c-e5f9e062b0f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Sentence: un suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis suis\n"
          ]
        }
      ]
    }
  ]
}